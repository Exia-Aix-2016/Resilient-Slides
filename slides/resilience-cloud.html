<section  data-transition="convex">

  <!--INTRO-->
  <section data-background-image="https://i.imgur.com/f6jWfPa.jpg">
    <h2 style="text-shadow: 2px 2.5px rgba(0, 0, 0, 0.70); margin-top: -20%; color: white; text-align: left; margin-left: -20%;">
      Les technologies résilientes </h2>
    <h2 style="text-shadow: 2px 2.5px rgba(0, 0, 0, 0.70); margin-top: -40px; color: white; text-align: left; margin-left: -20%;">
      du cloud computing </h2>

    <aside class="notes">
      Au cours de l'é

    </aside>
  </section>

   <!--HISTOIRE d'internet-->
   <section data-background-image="https://i.imgur.com/r8eLaVe.jpg">

    <h2 style="text-shadow: 2px 2.5px rgba(0, 0, 0, 0.70); margin-top: auto; margin-right: -50%; color: white;">
      Histoire d'internet
    </h2>
    
    <img style="margin-right: -70%;" src="/images/histinternet.png">
    <aside data-markdown class="notes">
**Début d'une grande histoire**

Le point de départ d'internet fût la naissance d'Arpanet en 1969, après plusieurs années de recherche. Ce réseau comprenait quatre ordinateurs mis en service à l'université de Los Angeles en Californie. Dans les années qui ont suivi de plus en plus d'université et d'institut de recherche ont rejoints le réseau.

Entre 1972 et 1976 sont réalisées les premières spécifications des protocoles internet (TCP, Telnet, UCP, FTP).

En 1979 est créé à l'université de Caroline du Nord et à l'université de Duke, Usenet (Unix user network), un système de réseau de forums. L'utilisateur accède aux forums via un logiciel communément appelé un lecteur de nouvelles.
Usenet, à l'origine indépendant, a rapidement été connecté à ARPAnet.

**La naissance d'internet**

En 1973 est publié à la conférence de l'INWG la suite de protocoles TCP/IP (Transfert Control Protocol - Internet Protocol), puis en 1983 Arpanet adopte cette suite de protocoles, c'est la naissance d'internet, grâce à ces protocoles les réseaux peuvent s'interconnecter. Finalement Arpanet est intégré au NSFNET (réseau de la National Science Foundation) en 1990. Ce réseau est le point de départ d'Internet.

**Un croissance fulgurante**

Depuis 1990 des millions de particuliers et entreprises rejoignent Internet, cet afflux massif à permit aux gens à travers le monde d'échanger et aux entreprises de faire évoluer leur business. Très rapidement les besoins d'internet se multiplie :

- La recherche d'information.

- Echange d'information via mail, forum, chat.

- Téléphonie.

- Jeu en ligne.

- Commerce électronique.

- Echange boursier.

- Réseau sociaux.

- et à l'avenir l'internet des objets...

On le comprend plus internet grandit, plus les usages s'étendent.

Aujourd'hui internet est utilisé partout dans le monde par 4.39 milliards d'individu qui y passe six heures en moyenne par jour...

**Un problème d'échelle et de criticité**

Cependant, cet afflux massif d'individu que ce soit des particuliers ou des organismes et l'utilisation grandissante d'internet pour des systèmes de plus en plus critiques a mis en lumière des problématiques d'ordre technologiques des infrastructures supportant internet ou fournissant des services via celui-ci.

En effet il aura fallut aux ingénieurs et aux chercheurs, trouver des solutions pour rendre les systèmes capables de répondre d'une part à cette demande intense et d'une autre part, puisque Internet s'utilisait de plus en plus pour des utilisations critiques, rendre ces systèmes plus robuste face à des événements perturbateurs.

    </aside>
  </section>
  
<!--Technologies-->
<section data-background-color="rgb(29, 35, 49)">

  <h2 style="text-shadow: 2px 2.5px rgba(0, 0, 0, 0.70); margin-top: auto; color: white;">
    Technologies &
    Techniques
  </h2>
  
  <img style=" width: 55%;" src="/images/cartographyresilience.png">
  <aside data-markdown class="notes">
  Au cours de ces années des technologies plus innovantes 
  les unes que les autres ont vu le jour dans le but de répondre
  à des problèmes d'ordre de résilience

  *Les conditions défavorables sont des états internes ou externes 
  aux systèmes qui peuvent perturber ou conduire à la perturbation 
  des capacités critiques.

  *Les événements indésirables sont des incidents qui perturbent les 
  capacités critiques en causant des dommages aux biens associés.

  </aside>
</section>

<!--Répondre à la demande-->
<section data-background-image="https://i.imgur.com/r8eLaVe.jpg">
  <h2 style="text-shadow: 2px 2.5px rgba(0, 0, 0, 0.70); margin-top: auto; margin-right: -55%; color: white;">
    Répondre à la demande
  </h2>
  <aside data-markdown class="notes">
  la première approche utilisée par les entreprises, 
  consistait à centraliser le stockage et le traitement
  des données dans un serveur central. Un des premiers
  obstacles rencontré était de répondre à la demande 
  grandissante pour un service donné, pensez aux moteurs 
  de recherche, aux sites d'achat, de streaming, le nombre 
  d'utilisateurs n'a cessé d'augmenter, cette augmentation 
  implique d'utiliser de plus en plus de ressources pour y répondre. 
  Un seul serveur ne suffisait plus...

  </aside>
</section>

<!--Scalabilité-->
<section data-background-color="rgb(29, 35, 49)">

  <h2 style="text-shadow: 2px 2.5px rgba(0, 0, 0, 0.70); margin-top: auto; color: white;">
    Scalabilité
  </h2>
  
  <img style=" width: 55%;" src="/images/scalability.png">
  <aside data-markdown class="notes">
  - Parler des deux approches

  - Parler des limites...
  Pour horizontal : c'est aussi applicatif.

  </aside>
</section>

<!--LoadBalancing-->
<section data-background-color="rgb(29, 35, 49)">
  <h2 style="text-shadow: 2px 2.5px rgba(0, 0, 0, 0.70); margin-top: auto; color: white;">
    Répartition de charge
  </h2>

  <table style="margin: 0 auto;">
 
    <tr>
    <td style="border-bottom: 0px solid; text-align: center; color: white;">Statique</td>
    <td style="border-bottom: 0px solid; border-left: 3px solid white; text-align: center; color: white;">Dynamique</td>
    </tr>
    <tr >
    <td  style="width: 50%;"><img  src="/images/dnsroundrobin.png"></td>
    <td style="border-left: 3px solid white; width: 70%;"><img   src="/images/proxying.png"></td>
    </tr>
    </table>
  <aside data-markdown class="notes">
    Parler du Geographic dns
  </aside>
</section>

<!--Virtualisation-->
<section data-background-color="rgb(29, 35, 49)">
  <h2 style="text-shadow: 2px 2.5px rgba(0, 0, 0, 0.70); margin-top: auto; color: white;">
    Virtualisation
  </h2>
  <img   src="/images/virtualisation.png">

  <aside data-markdown class="notes">
  Avant, les applications adoptaient une 
  architecture monolithique qui, bien que simple à déployer, 
  était compliquée à gérer quand déployées sur le même serveur.
  De plus, avec la montée en puissance d'internet, de plus en plus 
  d'entreprises voient leur système d'information subir des cyberattaques,
  pouvant endommager leur système hôte. Les organismes ont donc besoin de
  système sécurisé, d'être capable de migrer facilement leur solution 
  logicielle et de déployer efficacement sur leur infrastructure.
  En 1960 la firme IBM créé le premier système de virtualisation de serveur,
  au cours des années 80-90 l'apparition de l'architecture processeur x86 démocratise le principe,
  ce qui vient répondre aux problématiques citées ci-dessus. 

  Utilisation optimale des ressources du parc informatique.

  Installation, déploiement, migration facilité des applications du système d'information.

  Economie matériel et énergétique en mutualisant les ressources.

  Permet de mettre en place des environnements de testes pour les équipes de développement, ce qui améliore la qualité.

  Sécurisation des systèmes grâce à l'isolation des systèmes hôte et des réseaux.

  Allocation dynamique des ressources allouées aux systèmes virtualisés.

  </aside>
</section>
<!--Conteneurisation-->
<section data-background-color="rgb(29, 35, 49)">
  <h2 style="text-shadow: 2px 2.5px rgba(0, 0, 0, 0.70); margin-top: auto; color: white;">
    Conteneurisation
  </h2>
  <img   src="/images/containervsvirtua.png">
  <aside data-markdown class="notes">

  Dès le début des années 2000, le concept de containeurisation 
  se développe, l'idée n'est plus de virtualiser un système d'exploitation 
  qui fait ensuite tourner une application métier, 
  mais de virtualiser chaque application.

  Les conteneurs encapsulent un package applicatif qui comprends seulement le code de l'application, 
  ses dépendances et ses fichiers de configuration. 
  Pour fonctionner les conteneurs font appel à un logiciel qui s'occupera de les exécuter et les gérer.

  Portabilité : Cette approche permet notamment de rendre chaque application portable, chaque conteneur peut être déployé autant sur une machine Linux ou Windows ou même dans un système virtualisé.

  Légèreté : Les conteneurs partagent le même noyau système, celui de la machine, il n'y a aucun système virtualisé nécessaire à les faire fonctionner, cela demande moins de ressources au serveur. De plus, contrairement à une machine virtuelle standard, un conteneur mettra beaucoup moins de temps à démarrer.

  Scalable : La scalabilité est facilitée, puisqu'il est facile de dupliquer un conteneur.

  Sécurisé : Les applications sont isolées les unes des autres, ce qui empêche en principe la transmission d'un code malveillant à un autre conteneur ou à l'hôte.   

  </aside>
</section>

<!--Orchestration-->
<section data-background-color="rgb(29, 35, 49)">
  <h2 style="text-shadow: 2px 2.5px rgba(0, 0, 0, 0.70); margin-top: auto; color: white;">
    Orchestration
  </h2>
  <img   src="/images/orchestration.png">

  <aside data-markdown class="notes">

  L'orchestration permet d'automatiser le déploiement
  et la gestion de la mise à l'échelle (scalabilité)
  et la mise en réseau des conteneurs.

  L'orchestrateur va s'occuper de répartir les conteneurs 
  sur les différents serveurs, selon les besoins en matière 
  de mémoire et de CPU. Il va notamment s'occuper de 
  surveiller l'activité des conteneurs pour connaitre à 
  tout instant leur état de santé. En cas de mise en défaut 
  d'un conteneur, l'orchestrateur peut le redémarrer voir le 
  supprimer et en recréer un. Si un des serveurs est indisponible,
  il peut redémarrer les conteneurs sur un autre serveur.

  L'orchestrateur permet d'assurer la mise à jour des conteneurs de manière successive sans induire d'indisponibilité, c'est ce que l'on nomme le rolling update. Il peut aussi revenir en arrière en cas de problème.

  Les conteneurs étant par nature volatile, les informations réseau 
  de chaque conteneur (ex: adresse IP) est variable. L'orchestrateur
  offre un niveau d'abstraction permettant de regrouper un ou plusieurs 
  conteneurs, de leur allouer une adresse IP fixe et de l'exposer 
  à d'autres conteneurs.
  Ces fonctions confèrent à l'infrastructure un niveau de résilience accru.

  </aside>
</section>

<!--Clusterisation-->
<section data-background-color="rgb(29, 35, 49)">
  <h2 style="text-shadow: 2px 2.5px rgba(0, 0, 0, 0.70); margin-top: auto; color: white;">
    Clusterisation
  </h2>
  <img   src="/images/cluster.png">

  <aside data-markdown class="notes">
    Dès la fin des années 1980, les ingénieurs 
    développent un multi-ordinateur : l'idée est de fusionner 
    les ressources fournit par plusieurs ordinateurs pour 
    en former un nouveau qui sera virtuel. C'est ce qu'on 
    appel une grappe serveur ou un cluster.

    Cette approche va de pair avec les techniques
     visant à mieux répartir la charge, mais pas que. 
     En effet, cela permet d'augmenter la disponibilité, 
     de mieux gérer la scalabilité et de faciliter la gestion 
     des ressources (processeur, mémoire vive, stockage, bande passante...).
     Ici, on change de paradigme : les serveurs ne répondent pas individuellement 
     aux requêtes, mais forment un tout, qui y répondra, où 
     le calcule y est divisé entre les nœuds du cluster.
     Les avantages sont multiples :

     *Baisse des coûts : Le coût d’acquisition et de maintenance 
     d’un cluster est plus faible que le coût d’acquisition 
     d’un serveur central sur le long terme. En d’autres termes,
      il revient moins chère à une entreprise d’ajouter un nœud 
      à un cluster (scalabilité horizontale) que d’ajouter des 
      capacités supplémentaires à un serveur central (scalabilité vertical).
     
     *La scalabilité horizontale : Le regroupement d’ordinateurs en
      architecture distribuée possède une caractéristique très
      intéressante sur les clusters : la scalabilité horizontale.
      L’ajout d’un ordinateur supplémentaire dans un cluster 
      augmente de façon plus que proportionnelle la performance
      du cluster.
     
    * La haute disponibilité ou tolérance aux pannes : 
    Le regroupement d’ordinateurs en clusters permet de distribuer
     le traitement entre ceux-ci, ce qui offre la capacité au système
      de continuer à fonctionner malgré les défaillances, ce qui 
      n’est pas le cas dans les architectures centralisées dans 
      lesquelles la disponibilité de tout le système repose entièrement 
      sur un point : le serveur central (Single Point of Failure)

      Parler de la migration à chaud 
      
  
  </aside>
</section>

<!--Architecture micro-service-->
<section data-background-color="rgb(29, 35, 49)">
  <h2 style="text-shadow: 2px 2.5px rgba(0, 0, 0, 0.70); margin-top: auto; color: white;">
    Architecture micro-service
  </h2>
  <img   src="/images/archimicroservices.png">

  <aside data-markdown class="notes">

    En 2011 apparait le concept d'architecture
     micro-service, la philosophie s'inspire
      grandement de celle d'UNIX : "Ne faire qu'une seule chose et la faire bien". 
      L'idée n'est plus de structurer l'application en un seul bloc, 
      mais de découpler ses modules en un ensemble de services, 
      ces derniers communiquant ensemble par le biais d'interfaces
       commun.

       L'approche offre des avantages conséquents, elle facilite 
       le développement distribué, réduit les cycles de développement 
       puisque les équipes peuvent livrer chaque service indépendamment 
       des autres, facilite le déploiement, augmente la résilience : le faible couplage 
       entre les services permet qu'en cas de dysfonctionnement d'un des services que 
       l'application reste opérationnel.

    Néanmoins, l'approche comporte des challenges à relever : dorénavant il faut gérer 
    non plus une seule application, mais un essaim d'applications plus petite (micro-service) 
    qu'il faut être capable de gérer.

    Grâce à l'utilisation de conteneurs et d'orchestrateurs, il devient facile pour l'organisme 
    de déployer selon ses besoins, l'ensemble des micro-services sur son infrastructure.

  </aside>
</section>

<!--Réseau de diffusion de contenu-->
<section data-background-color="rgb(29, 35, 49)">
  <h2 style="text-shadow: 2px 2.5px rgba(0, 0, 0, 0.70); margin-top: auto; color: white;">
    Réseau de diffusion de contenu
  </h2>
  <img   src="/images/cdn.png">

  <aside data-markdown class="notes">

    Vers la fin des années 90' la technologie de 
    réseau de diffusion de contenu est créé, 
    constituée d'ordinateur en réseau, reliés 
    à travers internet ils coopèrent afin de mettre 
    à disposition le contenu d'un serveur principal.

    A noter : Si le serveur principal est tombé, le contenu est accessible.
  </aside>
</section>

<!--L'hyperconvergence-->
<section data-background-color="rgb(29, 35, 49)">
  <h2 style="text-shadow: 2px 2.5px rgba(0, 0, 0, 0.70); margin-top: auto; color: white;">
    L'Hyper-convergence
  </h2>
  <img   src="/images/hyperconvergence.png">

  <aside data-markdown class="notes">
    En 2012 apparait le terme d'Hyper-convergence, 
    l'idée est de pousser à son paroxysme le principe de cluster, 
    d'unicité, et de découpler drastiquement le matériel (serveur, routeur, commutateur, etc...) 
    de la partie logicielle, dans le but d'accroitre l'évolutivité et de réduire la complexité.

  </aside>
</section>

<!--La suite-->
<section data-background-color="rgb(29, 35, 49)">
  <h2 style="text-shadow: 2px 2.5px rgba(0, 0, 0, 0.70); margin-top: auto; color: white;">
    Pour finir...
  </h2>
  <img   src="">

  <aside data-markdown class="notes">


  </aside>
</section>