<section >

  <!--INTRO-->
  <section data-background-image="https://i.imgur.com/LcrrGy8.png">
    <h2 style="text-align: left; margin-left: -16%;">
      Les technologies <br />
      résilientes  <br />
      du cloud computing
    </h2>
    <aside class="notes">


    </aside>
  </section>


  <section>
    <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/d/db/Mod%C3%A8le-client-serveur.svg/1200px-Mod%C3%A8le-client-serveur.svg.png"/>
    <aside data-markdown class="notes">
      Parler des rôles client/serveur cette approche cause plein de petits soucis
    </aside>
  </section>

<!--Technologies-->
<section>
  <h2 style="margin-top: auto;">
    Technologies & Techniques
  </h2>
  <img style=" width: 55%;" src="/images/cartographyresilience.png">
  <aside data-markdown class="notes">
  Au cours de ces années des technologies plus innovantes 
  les unes que les autres ont vu le jour dans le but de répondre
  à des problèmes d'ordre de résilience

  *Les conditions défavorables sont des états internes ou externes 
  aux systèmes qui peuvent perturber ou conduire à la perturbation 
  des capacités critiques.

  *Les événements indésirables sont des incidents qui perturbent les 
  capacités critiques en causant des dommages aux biens associés.

  </aside>
</section>



<!--Répondre à la demande-->
<section data-background-image="https://i.imgur.com/LcrrGy8.png">
  <h2 style="text-align: left; margin-left: -16%;">
    Répondre <br /> à la demande
  </h2>
  <aside data-markdown class="notes">
  la première approche utilisée par les entreprises, 
  consistait à centraliser le stockage et le traitement
  des données dans un serveur central. Un des premiers
  obstacles rencontré était de répondre à la demande 
  grandissante pour un service donné, pensez aux moteurs 
  de recherche, aux sites d'achat, de streaming, le nombre 
  d'utilisateurs n'a cessé d'augmenter, cette augmentation 
  implique d'utiliser de plus en plus de ressources pour y répondre. 
  Un seul serveur ne suffisait plus...

  </aside>
</section>

<!--Scalabilité-->
<section>

  <h2>
    Scalabilité
  </h2>
  
  <img style=" width: 55%;" src="/images/scalability.png">
  <aside data-markdown class="notes">
  - Parler des deux approches

  - Parler des limites...
  Pour horizontal : c'est aussi applicatif.

  </aside>
</section>

<!--LoadBalancing-->
<section>
  <h2>
    Répartition de charge
  </h2>
  <div style="margin-left: -16%; display: flex; width: 130%;">
    <div>
      <h3> Statique</h3>
      <img  src="/images/dnsroundrobin.png">
    </div>
    <div style="width: 5px; margin: 6px 0; background: black;"></div>
    <div>
      <h3> Dynamique</h3>
      <img  src="/images/proxying.png">
    </div>
  </div>
  
  <aside data-markdown class="notes">
    Parler du Geographic dns
  </aside>
</section>

<!--Virtualisation-->
<section>
  <h2>
    Virtualisation
  </h2>
  <img style="width: 55%;"   src="/images/virtualisation.png">

  <aside data-markdown class="notes">
  Avant, les applications adoptaient une 
  architecture monolithique qui, bien que simple à déployer, 
  était compliquée à gérer quand déployées sur le même serveur.
  De plus, avec la montée en puissance d'internet, de plus en plus 
  d'entreprises voient leur système d'information subir des cyberattaques,
  pouvant endommager leur système hôte. Les organismes ont donc besoin de
  système sécurisé, d'être capable de migrer facilement leur solution 
  logicielle et de déployer efficacement sur leur infrastructure.
  En 1960 la firme IBM créé le premier système de virtualisation de serveur,
  au cours des années 80-90 l'apparition de l'architecture processeur x86 démocratise le principe,
  ce qui vient répondre aux problématiques citées ci-dessus. 

  Utilisation optimale des ressources du parc informatique.

  Installation, déploiement, migration facilité des applications du système d'information.

  Economie matériel et énergétique en mutualisant les ressources.

  Permet de mettre en place des environnements de testes pour les équipes de développement, ce qui améliore la qualité.

  Sécurisation des systèmes grâce à l'isolation des systèmes hôte et des réseaux.

  Allocation dynamique des ressources allouées aux systèmes virtualisés.

  </aside>
</section>
<!--Conteneurisation-->
<section>
  <h2>
    Conteneurisation
  </h2>
  <img src="/images/containervsvirtua.png">
  <aside data-markdown class="notes">

  Dès le début des années 2000, le concept de containeurisation 
  se développe, l'idée n'est plus de virtualiser un système d'exploitation 
  qui fait ensuite tourner une application métier, 
  mais de virtualiser chaque application.

  Les conteneurs encapsulent un package applicatif qui comprends seulement le code de l'application, 
  ses dépendances et ses fichiers de configuration. 
  Pour fonctionner les conteneurs font appel à un logiciel qui s'occupera de les exécuter et les gérer.

  Portabilité : Cette approche permet notamment de rendre chaque application portable, chaque conteneur peut être déployé autant sur une machine Linux ou Windows ou même dans un système virtualisé.

  Légèreté : Les conteneurs partagent le même noyau système, celui de la machine, il n'y a aucun système virtualisé nécessaire à les faire fonctionner, cela demande moins de ressources au serveur. De plus, contrairement à une machine virtuelle standard, un conteneur mettra beaucoup moins de temps à démarrer.

  Scalable : La scalabilité est facilitée, puisqu'il est facile de dupliquer un conteneur.

  Sécurisé : Les applications sont isolées les unes des autres, ce qui empêche en principe la transmission d'un code malveillant à un autre conteneur ou à l'hôte.   

  </aside>
</section>


<!--Clusterisation-->
<section >
  <h2>
    Clusterisation
  </h2>
  <img style="width: 50%;"  src="/images/cluster.png">

  <aside data-markdown class="notes">
    Dès la fin des années 1980, les ingénieurs 
    développent un multi-ordinateur : l'idée est de fusionner 
    les ressources fournit par plusieurs ordinateurs pour 
    en former un nouveau qui sera virtuel. C'est ce qu'on 
    appel une grappe serveur ou un cluster.

    Cette approche va de pair avec les techniques
     visant à mieux répartir la charge, mais pas que. 
     En effet, cela permet d'augmenter la disponibilité, 
     de mieux gérer la scalabilité et de faciliter la gestion 
     des ressources (processeur, mémoire vive, stockage, bande passante...).
     Ici, on change de paradigme : les serveurs ne répondent pas individuellement 
     aux requêtes, mais forment un tout, qui y répondra, où 
     le calcule y est divisé entre les nœuds du cluster.
     Les avantages sont multiples :

     *Baisse des coûts : Le coût d’acquisition et de maintenance 
     d’un cluster est plus faible que le coût d’acquisition 
     d’un serveur central sur le long terme. En d’autres termes,
      il revient moins chère à une entreprise d’ajouter un nœud 
      à un cluster (scalabilité horizontale) que d’ajouter des 
      capacités supplémentaires à un serveur central (scalabilité vertical).
     
     *La scalabilité horizontale : Le regroupement d’ordinateurs en
      architecture distribuée possède une caractéristique très
      intéressante sur les clusters : la scalabilité horizontale.
      L’ajout d’un ordinateur supplémentaire dans un cluster 
      augmente de façon plus que proportionnelle la performance
      du cluster.
     
    * La haute disponibilité ou tolérance aux pannes : 
    Le regroupement d’ordinateurs en clusters permet de distribuer
     le traitement entre ceux-ci, ce qui offre la capacité au système
      de continuer à fonctionner malgré les défaillances, ce qui 
      n’est pas le cas dans les architectures centralisées dans 
      lesquelles la disponibilité de tout le système repose entièrement 
      sur un point : le serveur central (Single Point of Failure)

      Parler de la migration à chaud 
      
  
  </aside>
</section>

<!--Orchestration-->
<section >
  <h2>
    Orchestration
  </h2>
  <img style="width: 50%;"   src="/images/orchestration.png">

  <aside data-markdown class="notes">

  L'orchestration permet d'automatiser le déploiement
  et la gestion de la mise à l'échelle (scalabilité)
  et la mise en réseau des conteneurs.

  L'orchestrateur va s'occuper de répartir les conteneurs 
  sur les différents serveurs, selon les besoins en matière 
  de mémoire et de CPU. Il va notamment s'occuper de 
  surveiller l'activité des conteneurs pour connaitre à 
  tout instant leur état de santé. En cas de mise en défaut 
  d'un conteneur, l'orchestrateur peut le redémarrer voir le 
  supprimer et en recréer un. Si un des serveurs est indisponible,
  il peut redémarrer les conteneurs sur un autre serveur.

  L'orchestrateur permet d'assurer la mise à jour des conteneurs de manière successive 
  sans induire d'indisponibilité, c'est ce que l'on nomme le rolling update.
   Il peut aussi revenir en arrière en cas de problème.

  Les conteneurs étant par nature volatile, les informations réseau 
  de chaque conteneur (ex: adresse IP) est variable. L'orchestrateur
  offre un niveau d'abstraction permettant de regrouper un ou plusieurs 
  conteneurs, de leur allouer une adresse IP fixe et de l'exposer 
  à d'autres conteneurs.
  Ces fonctions confèrent à l'infrastructure un niveau de résilience accru.

  </aside>
</section>


<!--Architecture micro-service-->
<section >
  <h2>
    Architecture micro-service
  </h2>
  <img   src="/images/archimicroservices.png">

  <aside data-markdown class="notes">

    En 2011 apparait le concept d'architecture
     micro-service, la philosophie s'inspire
      grandement de celle d'UNIX : "Ne faire qu'une seule chose et la faire bien". 
      L'idée n'est plus de structurer l'application en un seul bloc, 
      mais de découpler ses modules en un ensemble de services, 
      ces derniers communiquant ensemble par le biais d'interfaces
       commun.

       L'approche offre des avantages conséquents, elle facilite 
       le développement distribué, réduit les cycles de développement 
       puisque les équipes peuvent livrer chaque service indépendamment 
       des autres, facilite le déploiement, augmente la résilience : le faible couplage 
       entre les services permet qu'en cas de dysfonctionnement d'un des services que 
       l'application reste opérationnel.

    Néanmoins, l'approche comporte des challenges à relever : dorénavant il faut gérer 
    non plus une seule application, mais un essaim d'applications plus petite (micro-service) 
    qu'il faut être capable de gérer.

    Grâce à l'utilisation de conteneurs et d'orchestrateurs, il devient facile pour l'organisme 
    de déployer selon ses besoins, l'ensemble des micro-services sur son infrastructure.

  </aside>
</section>

<!--Réseau de diffusion de contenu-->
<section >
  <h2>
    Réseau de diffusion de contenu
  </h2>
  <img style="width: 80%;"   src="/images/cdn.png">

  <aside data-markdown class="notes">

    Vers la fin des années 90' la technologie de 
    réseau de diffusion de contenu est créé, 
    constituée d'ordinateur en réseau, reliés 
    à travers internet ils coopèrent afin de mettre 
    à disposition le contenu d'un serveur principal.

    A noter : Si le serveur principal est tombé, le contenu est accessible.
  </aside>
</section>

<!--La suite-->
<section data-background-image="https://i.imgur.com/LcrrGy8.png">

  <h2 style="text-align: left; margin-left: -16%;">
    En Résumé...
  </h2>
  <aside data-markdown class="notes">
    Rapeler ce qu'on a vue.
    Ces techno c'est le socles des cloud aujourd'hui
  </aside>
</section>
</section>